{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b09d7a19-5848-43f4-9d91-f35d4e8614b0",
      "metadata": {
        "id": "b09d7a19-5848-43f4-9d91-f35d4e8614b0"
      },
      "source": [
        "# 1. Information about the submission"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e37cb5bb-f3d0-4c11-a1dc-2490a208fcd3",
      "metadata": {
        "id": "e37cb5bb-f3d0-4c11-a1dc-2490a208fcd3"
      },
      "source": [
        "## 1.1 Name and number of the assignment "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e9d00b8-f3e5-4a44-bcc6-35cdd60767a9",
      "metadata": {
        "id": "4e9d00b8-f3e5-4a44-bcc6-35cdd60767a9"
      },
      "source": [
        "Assignment 1 Text Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64ba7f63-66ec-4691-a5d2-17f4679e298d",
      "metadata": {
        "id": "64ba7f63-66ec-4691-a5d2-17f4679e298d"
      },
      "source": [
        "## 1.2 Student name"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc8a4e09-62cc-43fd-a7a7-3e9d55ec13b2",
      "metadata": {
        "id": "cc8a4e09-62cc-43fd-a7a7-3e9d55ec13b2"
      },
      "source": [
        "Prateek Rajput"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a46ab45-d215-41af-b910-63ff4a215a07",
      "metadata": {
        "id": "8a46ab45-d215-41af-b910-63ff4a215a07"
      },
      "source": [
        "## 1.3 Codalab user ID"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b15cd6b5-8e20-4287-b6ea-a7b0904b355a",
      "metadata": {
        "id": "b15cd6b5-8e20-4287-b6ea-a7b0904b355a"
      },
      "source": [
        "pkrajput7"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70456c74-8e1f-4da0-bebe-fbceee169115",
      "metadata": {
        "id": "70456c74-8e1f-4da0-bebe-fbceee169115"
      },
      "source": [
        "## 1.4 Additional comments"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b810ac6-7739-4f7f-8bea-dbf1198570ea",
      "metadata": {
        "id": "6b810ac6-7739-4f7f-8bea-dbf1198570ea"
      },
      "source": [
        "The accuracy in the report for my final implementation is missing because the model took too more time to train than anticipated, I will put both of the f1 scores in comments. Please pardon me for this. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1af498ab-3c00-4d36-a962-c947862fede8",
      "metadata": {
        "id": "1af498ab-3c00-4d36-a962-c947862fede8"
      },
      "source": [
        "# 2. Technical Report"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b3c18a6-868b-4357-a308-7f6dff05c3d0",
      "metadata": {
        "id": "9b3c18a6-868b-4357-a308-7f6dff05c3d0"
      },
      "source": [
        "*Use Section 2 to describe results of your experiments as you would do writing a paper about your results. DO NOT insert code in this part. Only insert plots and tables summarizing results as needed. Use formulas if needed do described your methodology. The code is provided in Section 3.*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "061f71b9-114a-4cb0-b531-5711970317bf",
      "metadata": {
        "id": "061f71b9-114a-4cb0-b531-5711970317bf"
      },
      "source": [
        "## 2.1 Methodology "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c327f43e-ed30-4279-bba2-a97b2f8ef9e3",
      "metadata": {
        "id": "c327f43e-ed30-4279-bba2-a97b2f8ef9e3"
      },
      "source": [
        "1) Tokenizing and embeddings: I used the basic keras text tokenizer with padding. for embeddings I tried to use transformer models (BERT) and also ELMo to improve the result over the seminar baseline but the main problem was including it in the keras framework, I defined the special class for the Embedding layer but it kept giving an error about some layer superposition definition so finally I went with the native keras encoder \\\\\n",
        "\n",
        "2) size of the embedding vector and drop out: I changed the size of the embedding vector to 150 to capture some relational dynamics that the bi directional LSTM will capture and improve the accuracy of my implementation \\\\\n",
        "\n",
        "3) Bi directional LSTM and drop out: I tried bi directional LSTM instead of the unidirectional architecture and played around with the drop out rate for regularising because a super high accuracy on the training set was shuoting overfitted model to me ) I also tried to use the GRU cell instead of LSTMs but that did not work out quite well \\\\\n",
        "\n",
        "4) Spacial drop out: I eliminated the spacial drop out in the final implementation, just because it achieved the highest accuracy for me.\n",
        "\n",
        "Bidirectional LSTM:\n",
        "\n",
        "![image](https://analyticsindiamag.com/complete-guide-to-bidirectional-lstm-with-python-codes/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afe27e49-10c7-4c12-adea-48b0a05a5681",
      "metadata": {
        "id": "afe27e49-10c7-4c12-adea-48b0a05a5681"
      },
      "source": [
        "## 2.2 Discussion of results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5b1c84c-c261-46b5-a009-0f2bc4002752",
      "metadata": {
        "id": "b5b1c84c-c261-46b5-a009-0f2bc4002752"
      },
      "source": [
        "My initial implementation with LSTM RNN network was above baseline (results are indicated below) but my final implementation achieved a higher result as can be seen in the table\n",
        "\n",
        "Method | F1 stance detection | F1 stance classification\n",
        "--- | --- | ---\n",
        "Baseline | 0.4180 | 0.4355\n",
        "RNN (uni directional LSTM memory cell) | 0.4453 | 0.4564\n",
        "RNN (bi directional LSTM memory cell) |  | \n",
        "\n",
        "The LSTM network took 1.5 hrs to train while the bi Directional LSTM network took 3.5 hrs to train on 2 GPUs \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "194fecf1-e044-4210-a54b-aefbf4b4eebe",
      "metadata": {
        "id": "194fecf1-e044-4210-a54b-aefbf4b4eebe"
      },
      "source": [
        "# 3. Code"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a33ff9bd-62c6-4a63-8600-b1651420fee1",
      "metadata": {
        "id": "a33ff9bd-62c6-4a63-8600-b1651420fee1"
      },
      "source": [
        "*Enter here all code used to produce your results submitted to Codalab. Add some comments and subsections to navigate though your solution.*\n",
        "\n",
        "*In this part you are expected to develop yourself a solution of the task and provide a reproducible code:*\n",
        "- *Using Python 3;*\n",
        "- *Contains code for installation of all dependencies;*\n",
        "- *Contains code for downloading of all the datasets used*;\n",
        "- *Contains the code for reproducing your results (in other words, if a tester downloads your notebook she should be able to run cell-by-cell the code and obtain your experimental results as described in the methodology section)*.\n",
        "\n",
        "\n",
        "*As a result, you code will be graded according to these criteria:*\n",
        "- ***Readability**: your code should be well-structured preferably with indicated parts of your approach (Preprocessing, Model training, Evaluation, etc.).*\n",
        "- ***Reproducibility**: your code should be reproduced without any mistakes with “Run all” mode (obtaining experimental part).*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dff93e37-3a24-40ab-87db-16b537aad3f6",
      "metadata": {
        "id": "dff93e37-3a24-40ab-87db-16b537aad3f6"
      },
      "source": [
        "## 3.1 Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "73daa932-114b-4e28-9141-13b57c729435",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "73daa932-114b-4e28-9141-13b57c729435",
        "outputId": "7c11e2ff-a57f-400a-fb7c-e86aecf1eebc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dropout\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "#stopwords = set(stopwords.words('english'))\n",
        "from bs4 import BeautifulSoup\n",
        "import plotly.graph_objs as go\n",
        "#import plotly.plotly as py\n",
        "import cufflinks\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "import plotly.figure_factory as ff\n",
        "InteractiveShell.ast_node_interactivity = 'all'\n",
        "from plotly.offline import iplot\n",
        "cufflinks.go_offline()\n",
        "cufflinks.set_config_file(world_readable=True, theme='pearl')\n",
        "from nltk.corpus import stopwords\n",
        "from keras.layers import Bidirectional"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b3c19fa-f883-4675-9506-85c4f02f0af9",
      "metadata": {
        "id": "1b3c19fa-f883-4675-9506-85c4f02f0af9"
      },
      "source": [
        "## 3.2 Download the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8f366b0f-7d0b-44e0-bb82-0d82c3ea1bb1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f366b0f-7d0b-44e0-bb82-0d82c3ea1bb1",
        "outputId": "34025e9e-7c2a-4351-e800-76eb946c5113"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-17 19:08:50--  https://raw.githubusercontent.com/dialogue-evaluation/RuArg/main/data/train.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1539551 (1.5M) [text/plain]\n",
            "Saving to: ‘train.tsv’\n",
            "\n",
            "\rtrain.tsv             0%[                    ]       0  --.-KB/s               \rtrain.tsv           100%[===================>]   1.47M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2022-04-17 19:08:50 (21.1 MB/s) - ‘train.tsv’ saved [1539551/1539551]\n",
            "\n",
            "--2022-04-17 19:08:50--  https://raw.githubusercontent.com/dialogue-evaluation/RuArg/main/data/val_empty.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 308303 (301K) [text/plain]\n",
            "Saving to: ‘val_empty.tsv’\n",
            "\n",
            "val_empty.tsv       100%[===================>] 301.08K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2022-04-17 19:08:50 (7.41 MB/s) - ‘val_empty.tsv’ saved [308303/308303]\n",
            "\n",
            "--2022-04-17 19:08:51--  https://raw.githubusercontent.com/dialogue-evaluation/RuArg/main/data/test-no_labels.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 298180 (291K) [text/plain]\n",
            "Saving to: ‘test-no_labels.tsv’\n",
            "\n",
            "test-no_labels.tsv  100%[===================>] 291.19K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2022-04-17 19:08:51 (7.25 MB/s) - ‘test-no_labels.tsv’ saved [298180/298180]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O train.tsv https://raw.githubusercontent.com/dialogue-evaluation/RuArg/main/data/train.tsv\n",
        "!wget -O val_empty.tsv https://raw.githubusercontent.com/dialogue-evaluation/RuArg/main/data/val_empty.tsv\n",
        "!wget -O test-no_labels.tsv https://raw.githubusercontent.com/dialogue-evaluation/RuArg/main/data/test-no_labels.tsv\n",
        "# if some needed file is not in the public domain use google drive or other free hosting to make them available"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"train.tsv\", sep=\"\\t\")\n",
        "val_df = pd.read_csv(\"val_empty.tsv\", sep=\"\\t\")\n",
        "test_df = pd.read_csv(\"test-no_labels.tsv\", sep=\"\\t\")"
      ],
      "metadata": {
        "id": "bqsBGOdTqQwk"
      },
      "id": "bqsBGOdTqQwk",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ed8aa6f0-79e0-4c7d-b6bc-2dcd48382af2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "ed8aa6f0-79e0-4c7d-b6bc-2dcd48382af2",
        "outputId": "f639d3b6-c5ba-4f2a-e292-699b42d1fd82"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   text_id                                               text  masks_stance  \\\n",
              "0    17024  [USER], согласно предписаниям Роспотребнадзора...            -1   \n",
              "1    17025  О несоблюдении карантинных мер контактными лиц...            -1   \n",
              "2    17027  [USER], читайте больше книжек на карантине, мо...            -1   \n",
              "3    17030  Иди почитай инсту наших городских пабликов где...            -1   \n",
              "4    17031  Все контактные лица, которых они обозначили, о...            -1   \n",
              "\n",
              "   masks_argument  quarantine_stance  quarantine_argument  vaccines_stance  \\\n",
              "0              -1                  1                    1               -1   \n",
              "1              -1                  1                    1               -1   \n",
              "2              -1                  1                    1               -1   \n",
              "3              -1                  1                    1               -1   \n",
              "4              -1                  1                    1               -1   \n",
              "\n",
              "   vaccines_argument  \n",
              "0                 -1  \n",
              "1                 -1  \n",
              "2                 -1  \n",
              "3                 -1  \n",
              "4                 -1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4092cc24-4ab7-4979-bc58-b8189ae66887\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>text</th>\n",
              "      <th>masks_stance</th>\n",
              "      <th>masks_argument</th>\n",
              "      <th>quarantine_stance</th>\n",
              "      <th>quarantine_argument</th>\n",
              "      <th>vaccines_stance</th>\n",
              "      <th>vaccines_argument</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17024</td>\n",
              "      <td>[USER], согласно предписаниям Роспотребнадзора...</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>17025</td>\n",
              "      <td>О несоблюдении карантинных мер контактными лиц...</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17027</td>\n",
              "      <td>[USER], читайте больше книжек на карантине, мо...</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17030</td>\n",
              "      <td>Иди почитай инсту наших городских пабликов где...</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17031</td>\n",
              "      <td>Все контактные лица, которых они обозначили, о...</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4092cc24-4ab7-4979-bc58-b8189ae66887')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4092cc24-4ab7-4979-bc58-b8189ae66887 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4092cc24-4ab7-4979-bc58-b8189ae66887');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1402"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[USER], согласно предписаниям Роспотребнадзора, все транзитные пассажиры, следующие через Москву, должны пройти 14-дневный карантин у себя по месту жительства.\n",
            "О несоблюдении карантинных мер контактными лицами можно сообщить на на горячую линию Роспотребнадзора - 8-800-100-0004 (можно позвонить бесплатно из любого населенного пункта России в рабочие дни с 10-00 до 17-00 (время московское), перерыв с 12-00 до 12-45) или в Единый консультационный центр Роспотребнадзора - 8-800-555-49-43.\n",
            "[USER], читайте больше книжек на карантине, может мозг реанимируете\n",
            "Иди почитай инсту наших городских пабликов где каждый 10ый пишет что у них знакомый откуда то вернулся и плевал на карантин, у нас никто ниче не раздает, раздавать нечего в аптеках нет ничего)\n",
            "Все контактные лица, которых они обозначили, отправлены на 14-дневный карантин, им сделают тестирование.\n",
            "[USER], многие находятся на домашнем карантине\n",
            "Если бы сразу запретили перелеты и ввели карантин, то никто бы не полетел никуда.\n",
            "[USER], надеемся, что в других регионах не придется вводить настолько жесткие меры по карантину\n",
            "[USER], почему доктор зойдберг не имеет песню про маски и карантин?\n",
            "вот из-за таких идиотов, которые ходят без масок и не сидят на карантине страдают все!\n"
          ]
        }
      ],
      "source": [
        "train_df.head()\n",
        "len(test_df)\n",
        "for elem in train_df.text[:10]:\n",
        "  print (elem)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "791dc0e7-337d-46ad-96a3-543a732f19e2",
      "metadata": {
        "id": "791dc0e7-337d-46ad-96a3-543a732f19e2"
      },
      "source": [
        "## 3.3 Preprocessing "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.2 \n",
        "!pip install keras==2.4.3"
      ],
      "metadata": {
        "id": "BQfNIPni2d7m"
      },
      "id": "BQfNIPni2d7m",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "from keras.engine import Layer"
      ],
      "metadata": {
        "id": "MjJxMdi9t6Fc"
      },
      "id": "MjJxMdi9t6Fc",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "class ModuleLayer(tf.keras.layers.Layer):\n",
        "\n",
        "  @staticmethod\n",
        "  def __init_session__(session):\n",
        "    tf.keras.backend.set_session(session)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bUcwUzTS4UuS"
      },
      "id": "bUcwUzTS4UuS",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b71a4653-86f2-448a-a2c4-17c02c1ba940",
      "metadata": {
        "tags": [],
        "id": "b71a4653-86f2-448a-a2c4-17c02c1ba940"
      },
      "outputs": [],
      "source": [
        "class ElmoEmbeddingLayer(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        self.dimensions = 1024\n",
        "        self.trainable=True\n",
        "        super(ElmoEmbeddingLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.elmo = hub.Module('https://tfhub.dev/google/elmo/2', trainable=self.trainable,\n",
        "                               name=\"{}_module\".format(self.name))\n",
        "\n",
        "        self.trainable_weights += K.tf.trainable_variables(scope=\"^{}_module/.*\".format(self.name))\n",
        "        super(ElmoEmbeddingLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        result = self.elmo(K.squeeze(K.cast(x, tf.string), axis=1),\n",
        "                      as_dict=True,\n",
        "                      signature='default',\n",
        "                      )['default']\n",
        "        return result\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return K.not_equal(inputs, '--PAD--')\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], self.dimensions)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23773d4e-e8d7-4e56-9610-4ee61b38c65a",
      "metadata": {
        "id": "23773d4e-e8d7-4e56-9610-4ee61b38c65a"
      },
      "source": [
        "## 3.4 My method of text processing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy==1.19.5"
      ],
      "metadata": {
        "id": "b82jmXPz7PKN"
      },
      "id": "b82jmXPz7PKN",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4aa2274-477a-46e6-95ff-ec98e633ab35",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4aa2274-477a-46e6-95ff-ec98e633ab35",
        "outputId": "0e447722-331b-43da-b3c4-57047a5e1ccc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250\n",
            "(6649, 250)\n",
            "(6649, 4)\n",
            "Epoch 1/10\n",
            "104/104 [==============================] - 131s 1s/step - loss: 0.8599 - accuracy: 0.6609\n",
            "Epoch 2/10\n",
            "104/104 [==============================] - 130s 1s/step - loss: 0.4622 - accuracy: 0.8057\n",
            "Epoch 3/10\n",
            "104/104 [==============================] - 130s 1s/step - loss: 0.3939 - accuracy: 0.8288\n",
            "Epoch 4/10\n",
            "104/104 [==============================] - 129s 1s/step - loss: 0.2685 - accuracy: 0.8949\n",
            "Epoch 5/10\n",
            "104/104 [==============================] - 129s 1s/step - loss: 0.1543 - accuracy: 0.9475\n",
            "Epoch 6/10\n",
            "104/104 [==============================] - 129s 1s/step - loss: 0.0858 - accuracy: 0.9725\n",
            "Epoch 7/10\n",
            "104/104 [==============================] - 127s 1s/step - loss: 0.0586 - accuracy: 0.9824\n",
            "Epoch 8/10\n",
            "104/104 [==============================] - 128s 1s/step - loss: 0.0359 - accuracy: 0.9896\n",
            "Epoch 9/10\n",
            "104/104 [==============================] - 128s 1s/step - loss: 0.0224 - accuracy: 0.9938\n",
            "Epoch 10/10\n",
            "104/104 [==============================] - 129s 1s/step - loss: 0.0160 - accuracy: 0.9962\n",
            "250\n",
            "(6649, 250)\n",
            "(6649, 4)\n",
            "Epoch 1/10\n",
            "104/104 [==============================] - 132s 1s/step - loss: 0.7044 - accuracy: 0.7282\n",
            "Epoch 2/10\n",
            "104/104 [==============================] - 138s 1s/step - loss: 0.3105 - accuracy: 0.8952\n",
            "Epoch 3/10\n",
            "104/104 [==============================] - 139s 1s/step - loss: 0.2452 - accuracy: 0.9057\n",
            "Epoch 4/10\n",
            "104/104 [==============================] - 136s 1s/step - loss: 0.2021 - accuracy: 0.9188\n",
            "Epoch 5/10\n",
            "104/104 [==============================] - 132s 1s/step - loss: 0.1427 - accuracy: 0.9431\n",
            "Epoch 6/10\n",
            "104/104 [==============================] - 126s 1s/step - loss: 0.0940 - accuracy: 0.9671\n",
            "Epoch 7/10\n",
            "104/104 [==============================] - 126s 1s/step - loss: 0.0516 - accuracy: 0.9844\n",
            "Epoch 8/10\n",
            "104/104 [==============================] - 126s 1s/step - loss: 0.0323 - accuracy: 0.9911\n",
            "Epoch 9/10\n",
            "104/104 [==============================] - 127s 1s/step - loss: 0.0215 - accuracy: 0.9947\n",
            "Epoch 10/10\n",
            "104/104 [==============================] - 127s 1s/step - loss: 0.0143 - accuracy: 0.9964\n",
            "250\n",
            "(6649, 250)\n",
            "(6649, 4)\n",
            "Epoch 1/10\n",
            "104/104 [==============================] - 127s 1s/step - loss: 0.6813 - accuracy: 0.7586\n",
            "Epoch 2/10\n",
            "104/104 [==============================] - 136s 1s/step - loss: 0.3021 - accuracy: 0.8810\n",
            "Epoch 3/10\n",
            "104/104 [==============================] - 137s 1s/step - loss: 0.2616 - accuracy: 0.8869\n",
            "Epoch 4/10\n",
            "104/104 [==============================] - 134s 1s/step - loss: 0.2006 - accuracy: 0.9140\n",
            "Epoch 5/10\n",
            "104/104 [==============================] - 136s 1s/step - loss: 0.1125 - accuracy: 0.9601\n",
            "Epoch 6/10\n",
            "104/104 [==============================] - 131s 1s/step - loss: 0.0681 - accuracy: 0.9761\n",
            "Epoch 7/10\n",
            "104/104 [==============================] - 127s 1s/step - loss: 0.0438 - accuracy: 0.9868\n",
            "Epoch 8/10\n",
            "104/104 [==============================] - 127s 1s/step - loss: 0.0260 - accuracy: 0.9928\n",
            "Epoch 9/10\n",
            "104/104 [==============================] - 127s 1s/step - loss: 0.0192 - accuracy: 0.9944\n",
            "Epoch 10/10\n",
            "104/104 [==============================] - 127s 1s/step - loss: 0.0123 - accuracy: 0.9970\n",
            "250\n",
            "(6649, 250)\n",
            "(6649, 4)\n",
            "Epoch 1/10\n",
            "104/104 [==============================] - 128s 1s/step - loss: 0.6055 - accuracy: 0.7801\n",
            "Epoch 2/10\n",
            "104/104 [==============================] - 130s 1s/step - loss: 0.2158 - accuracy: 0.9358\n",
            "Epoch 3/10\n",
            "104/104 [==============================] - 130s 1s/step - loss: 0.1684 - accuracy: 0.9457\n",
            "Epoch 4/10\n",
            "104/104 [==============================] - 129s 1s/step - loss: 0.1377 - accuracy: 0.9520\n",
            "Epoch 5/10\n",
            "104/104 [==============================] - 129s 1s/step - loss: 0.0982 - accuracy: 0.9644\n",
            "Epoch 6/10\n",
            "104/104 [==============================] - 128s 1s/step - loss: 0.0763 - accuracy: 0.9698\n",
            "Epoch 7/10\n",
            "104/104 [==============================] - 128s 1s/step - loss: 0.0677 - accuracy: 0.9785\n",
            "Epoch 8/10\n",
            "104/104 [==============================] - 130s 1s/step - loss: 0.0469 - accuracy: 0.9820\n",
            "Epoch 9/10\n",
            "104/104 [==============================] - 129s 1s/step - loss: 0.0300 - accuracy: 0.9917\n",
            "Epoch 10/10\n",
            "104/104 [==============================] - 129s 1s/step - loss: 0.0194 - accuracy: 0.9944\n",
            "250\n",
            "(6649, 250)\n",
            "(6649, 4)\n",
            "Epoch 1/10\n",
            " 25/104 [======>.......................] - ETA: 1:32 - loss: 0.9785 - accuracy: 0.7244"
          ]
        }
      ],
      "source": [
        "df1 = train_df[['masks_stance', 'masks_argument', 'quarantine_stance', 'quarantine_argument', 'vaccines_stance', 'vaccines_argument']]\n",
        "for col in df1:\n",
        "  # The maximum number of words to be used. (most frequent)\n",
        "  MAX_NB_WORDS = 50000\n",
        "  # Max number of words in each sequence\n",
        "  MAX_SEQUENCE_LENGTH = 250\n",
        "  EMBEDDING_DIM = 150\n",
        "\n",
        "  tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
        "  tokenizer.fit_on_texts(train_df['text'].values)\n",
        "  word_index = tokenizer.word_index\n",
        "\n",
        "  X = tokenizer.texts_to_sequences(train_df['text'].values)\n",
        "  X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "  print(X.shape[1])\n",
        "\n",
        "  Y = pd.get_dummies(train_df[col]).values \n",
        "\n",
        "  X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.01, random_state = 42)\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(ModuleLayer())\n",
        "  # model.add(ElmoEmbeddingLayer())\n",
        "  model.add(Embedding(20018, EMBEDDING_DIM, input_length=X.shape[1]))\n",
        "  model.add(SpatialDropout1D(0.5))\n",
        "  model.add(Bidirectional(LSTM(150)))\n",
        "  # model.add(LSTM(100, dropout=0.5, recurrent_dropout=0.5))\n",
        "  model.add(Dense(4, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  epochs = 10\n",
        "  batch_size = 64\n",
        "\n",
        "\n",
        "  print (X_train.shape)\n",
        "  print (Y_train.shape)\n",
        "  history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "  x = tokenizer.texts_to_sequences(test_df['text'].values)\n",
        "  x = pad_sequences(x, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "  predict_proba = model.predict(x)\n",
        "  predict = []\n",
        "  for prob in predict_proba:\n",
        "    predict.append(np.argmax(prob))\n",
        "\n",
        "  test_df[col] = predict\n",
        "  test_df[col] -= 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.to_csv('output7.tsv', index = False, sep='\\t')"
      ],
      "metadata": {
        "id": "rc1E704WqwXo"
      },
      "id": "rc1E704WqwXo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip output7.zip output7.tsv"
      ],
      "metadata": {
        "id": "T5m7KwP7qzPU"
      },
      "id": "T5m7KwP7qzPU",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "assignment-template.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}